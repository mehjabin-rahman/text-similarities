{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b5f24ee",
   "metadata": {},
   "source": [
    "#### Group membes:\n",
    "1. MEHJABIN RAHMAN -501200106\n",
    "2. MAISHA LABIBA-501191497"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af2d339",
   "metadata": {},
   "source": [
    "# PART1: Natural Language Processing- Finding Text Similarities\n",
    "This part is about finding similarities in text and document. By considering following sentences\n",
    "and using any similarity or a clustering methods ( e.g., k-Means or hierarchical clustering) show\n",
    "the more similar sentences. Use at least three methods from TF, TF-IDF, bag of the words\n",
    "Word2Vec or shingling techniques, and consequently, use a proper distance measure (e.g.,\n",
    "Jaccard, Cosine, Edit and Hamming distance) cluster following data and show the similarity\n",
    "between them. Note that if you want to create your own distance measure, you should prove it is\n",
    "a valid distance measure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96360589",
   "metadata": {},
   "source": [
    "###### First we import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7730040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd8bd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01fcf8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d58886c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acd34569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d5c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7adc5432",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences= {\n",
    "    \"Id\": [1, 2, 3, 4, 5,6],\n",
    "    \"Text\": [\n",
    "        \"In the past John liked only sport but now he likes sport and politics\",\n",
    "        \"Sam only liked politics but now he is fan of both music and politics\",\n",
    "        \"Sara likes both books and politics but in the past she only read books\",\n",
    "        \"Robert loved both books and nature but now he only reads books\",\n",
    "        \"Linda liked books and sport but she only likes sport now\",\n",
    "        \"Alison used to loved nature but currently she likes both nature and sport\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888d946e",
   "metadata": {},
   "source": [
    "###### We have preprocessed the dataset. We have converted the sentences in lower case, remove stop words. Also applied stemming and lemmatizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c007f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentence):\n",
    "    #converting to lowercase\n",
    "    sentence=sentence.lower()\n",
    "    #tokenization\n",
    "    words=word_tokenize(sentence)\n",
    "    #stemming\n",
    "    words=[stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    #lemmatization\n",
    "    words=[lemmatizer.lemmatize(word.lower()) for word in words]\n",
    "    \n",
    "    sentence=' '.join(words)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947fe2e5",
   "metadata": {},
   "source": [
    "###### After applying preprocessing, our dataset looks like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df27694e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Id': [1, 2, 3, 4, 5, 6],\n",
       " 'Text': ['past john like sport like sport polit',\n",
       "  'sam like polit fan music polit',\n",
       "  'sara like book polit past read book',\n",
       "  'robert love book natur read book',\n",
       "  'linda like book sport like sport',\n",
       "  'alison use love natur current like natur sport']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences['Text'] = [preprocessing(sentence) for sentence in sentences['Text']]\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6626d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans clustering is a method of clustering.\n",
    "def clustering(matrix):\n",
    "    number_of_clusters = 3\n",
    "    km = KMeans(n_clusters=number_of_clusters)\n",
    "    km.fit(matrix)\n",
    "   \n",
    "\n",
    "    # Print the cluster assignments for each sentence\n",
    "    for i, sentence in enumerate(sentences['Text']):\n",
    "        print(f\"Sentence {i+1}: {sentences['Text'][i]} Cluster {km.labels_[i]+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025562bf",
   "metadata": {},
   "source": [
    "###### To find the similarities between sentences, we have used three methods (Bag-of-words, TF, and TF-IDF). Also we have also used the cosine similarity to measure the distance. And using K-means clustering to show the similar sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1faaa7bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====================================\n",
      "--- TF with Cosine Similarity ---\n",
      "A list of features:\n",
      "====================\n",
      "['alison' 'book' 'current' 'fan' 'john' 'like' 'linda' 'love' 'music'\n",
      " 'natur' 'past' 'polit' 'read' 'robert' 'sam' 'sara' 'sport' 'use']\n",
      "Tf-weighted document-term matrix:\n",
      "======================================\n",
      "   alison      book  current       fan      john      like     linda  \\\n",
      "0   0.000  0.000000    0.000  0.000000  0.142857  0.285714  0.000000   \n",
      "1   0.000  0.000000    0.000  0.166667  0.000000  0.166667  0.000000   \n",
      "2   0.000  0.285714    0.000  0.000000  0.000000  0.142857  0.000000   \n",
      "3   0.000  0.333333    0.000  0.000000  0.000000  0.000000  0.000000   \n",
      "4   0.000  0.166667    0.000  0.000000  0.000000  0.333333  0.166667   \n",
      "5   0.125  0.000000    0.125  0.000000  0.000000  0.125000  0.000000   \n",
      "\n",
      "       love     music     natur      past     polit      read    robert  \\\n",
      "0  0.000000  0.000000  0.000000  0.142857  0.142857  0.000000  0.000000   \n",
      "1  0.000000  0.166667  0.000000  0.000000  0.333333  0.000000  0.000000   \n",
      "2  0.000000  0.000000  0.000000  0.142857  0.142857  0.142857  0.000000   \n",
      "3  0.166667  0.000000  0.166667  0.000000  0.000000  0.166667  0.166667   \n",
      "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "5  0.125000  0.000000  0.250000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "        sam      sara     sport    use  \n",
      "0  0.000000  0.000000  0.285714  0.000  \n",
      "1  0.166667  0.000000  0.000000  0.000  \n",
      "2  0.000000  0.142857  0.000000  0.000  \n",
      "3  0.000000  0.000000  0.000000  0.000  \n",
      "4  0.000000  0.000000  0.333333  0.000  \n",
      "5  0.000000  0.000000  0.125000  0.125  \n",
      "====================== \n",
      "\n",
      "k means clustering \n",
      "\n",
      "Sentence 1: past john like sport like sport polit Cluster 1\n",
      "Sentence 2: sam like polit fan music polit Cluster 3\n",
      "Sentence 3: sara like book polit past read book Cluster 2\n",
      "Sentence 4: robert love book natur read book Cluster 2\n",
      "Sentence 5: linda like book sport like sport Cluster 1\n",
      "Sentence 6: alison use love natur current like natur sport Cluster 1\n",
      "\n",
      "\n",
      "similarity matrix\n",
      "[[1.         0.42640143 0.40201513 0.         0.76277007 0.38138504]\n",
      " [0.42640143 1.         0.35355339 0.         0.2236068  0.1118034 ]\n",
      " [0.40201513 0.35355339 1.         0.58925565 0.42163702 0.10540926]\n",
      " [0.         0.         0.58925565 1.         0.2236068  0.3354102 ]\n",
      " [0.76277007 0.2236068  0.42163702 0.2236068  1.         0.4       ]\n",
      " [0.38138504 0.1118034  0.10540926 0.3354102  0.4        1.        ]]\n",
      "\n",
      "\n",
      "Most similar to sentence 1:\n",
      "\tSentence 5 with similarity score 0.7627700713964738\n",
      "Most similar to sentence 2:\n",
      "\tSentence 1 with similarity score 0.42640143271122083\n",
      "Most similar to sentence 3:\n",
      "\tSentence 4 with similarity score 0.5892556509887895\n",
      "Most similar to sentence 4:\n",
      "\tSentence 3 with similarity score 0.5892556509887895\n",
      "Most similar to sentence 5:\n",
      "\tSentence 1 with similarity score 0.7627700713964738\n",
      "Most similar to sentence 6:\n",
      "\tSentence 5 with similarity score 0.39999999999999997\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "--- Bag of words with Cosine Similarity ---\n",
      "A list of features:\n",
      "====================\n",
      "['alison' 'book' 'current' 'fan' 'john' 'like' 'linda' 'love' 'music'\n",
      " 'natur' 'past' 'polit' 'read' 'robert' 'sam' 'sara' 'sport' 'use']\n",
      "BOW-weighted document-term matrix:\n",
      "======================================\n",
      "   alison  book  current  fan  john  like  linda  love  music  natur  past  \\\n",
      "0       0     0        0    0     1     2      0     0      0      0     1   \n",
      "1       0     0        0    1     0     1      0     0      1      0     0   \n",
      "2       0     2        0    0     0     1      0     0      0      0     1   \n",
      "3       0     2        0    0     0     0      0     1      0      1     0   \n",
      "4       0     1        0    0     0     2      1     0      0      0     0   \n",
      "5       1     0        1    0     0     1      0     1      0      2     0   \n",
      "\n",
      "   polit  read  robert  sam  sara  sport  use  \n",
      "0      1     0       0    0     0      2    0  \n",
      "1      2     0       0    1     0      0    0  \n",
      "2      1     1       0    0     1      0    0  \n",
      "3      0     1       1    0     0      0    0  \n",
      "4      0     0       0    0     0      2    0  \n",
      "5      0     0       0    0     0      1    1  \n",
      "====================== \n",
      "\n",
      "k means clustering \n",
      "\n",
      "Sentence 1: past john like sport like sport polit Cluster 1\n",
      "Sentence 2: sam like polit fan music polit Cluster 1\n",
      "Sentence 3: sara like book polit past read book Cluster 2\n",
      "Sentence 4: robert love book natur read book Cluster 2\n",
      "Sentence 5: linda like book sport like sport Cluster 1\n",
      "Sentence 6: alison use love natur current like natur sport Cluster 3\n",
      "\n",
      "\n",
      "similarity matrix\n",
      "[[1.         0.42640143 0.40201513 0.         0.76277007 0.38138504]\n",
      " [0.42640143 1.         0.35355339 0.         0.2236068  0.1118034 ]\n",
      " [0.40201513 0.35355339 1.         0.58925565 0.42163702 0.10540926]\n",
      " [0.         0.         0.58925565 1.         0.2236068  0.3354102 ]\n",
      " [0.76277007 0.2236068  0.42163702 0.2236068  1.         0.4       ]\n",
      " [0.38138504 0.1118034  0.10540926 0.3354102  0.4        1.        ]]\n",
      "\n",
      "\n",
      "Most similar to sentence 1:\n",
      "\tSentence 5 with similarity score 0.7627700713964739\n",
      "Most similar to sentence 2:\n",
      "\tSentence 1 with similarity score 0.42640143271122083\n",
      "Most similar to sentence 3:\n",
      "\tSentence 4 with similarity score 0.5892556509887895\n",
      "Most similar to sentence 4:\n",
      "\tSentence 3 with similarity score 0.5892556509887895\n",
      "Most similar to sentence 5:\n",
      "\tSentence 1 with similarity score 0.7627700713964739\n",
      "Most similar to sentence 6:\n",
      "\tSentence 5 with similarity score 0.4\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "--- TF-IDF with Cosine Similarity ---\n",
      "A list of features:\n",
      "====================\n",
      "['alison' 'book' 'current' 'fan' 'john' 'like' 'linda' 'love' 'music'\n",
      " 'natur' 'past' 'polit' 'read' 'robert' 'sam' 'sara' 'sport' 'use']\n",
      "Tf-idf-weighted document-term matrix:\n",
      "======================================\n",
      "    alison      book  current       fan      john      like     linda  \\\n",
      "0  0.00000  0.000000  0.00000  0.000000  0.441993  0.452889  0.000000   \n",
      "1  0.00000  0.000000  0.00000  0.439389  0.000000  0.225111  0.000000   \n",
      "2  0.00000  0.618987  0.00000  0.000000  0.000000  0.229032  0.000000   \n",
      "3  0.00000  0.623322  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
      "4  0.00000  0.328320  0.00000  0.000000  0.000000  0.485929  0.474237   \n",
      "5  0.37519  0.000000  0.37519  0.000000  0.000000  0.192220  0.000000   \n",
      "\n",
      "       love     music     natur      past     polit      read    robert  \\\n",
      "0  0.000000  0.000000  0.000000  0.362440  0.305997  0.000000  0.000000   \n",
      "1  0.000000  0.439389  0.000000  0.000000  0.608389  0.000000  0.000000   \n",
      "2  0.000000  0.000000  0.000000  0.366582  0.309494  0.366582  0.000000   \n",
      "3  0.369149  0.000000  0.369149  0.000000  0.000000  0.369149  0.450174   \n",
      "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "5  0.307662  0.000000  0.615323  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "        sam      sara     sport      use  \n",
      "0  0.000000  0.000000  0.611994  0.00000  \n",
      "1  0.439389  0.000000  0.000000  0.00000  \n",
      "2  0.000000  0.447043  0.000000  0.00000  \n",
      "3  0.000000  0.000000  0.000000  0.00000  \n",
      "4  0.000000  0.000000  0.656641  0.00000  \n",
      "5  0.000000  0.000000  0.259749  0.37519  \n",
      "====================== \n",
      "\n",
      "k means clustering \n",
      "\n",
      "Sentence 1: past john like sport like sport polit Cluster 1\n",
      "Sentence 2: sam like polit fan music polit Cluster 3\n",
      "Sentence 3: sara like book polit past read book Cluster 2\n",
      "Sentence 4: robert love book natur read book Cluster 2\n",
      "Sentence 5: linda like book sport like sport Cluster 1\n",
      "Sentence 6: alison use love natur current like natur sport Cluster 1\n",
      "\n",
      "\n",
      "similarity matrix\n",
      "[[1.         0.28811542 0.33129449 0.         0.62193243 0.24601928]\n",
      " [0.28811542 1.         0.23985016 0.         0.10938785 0.04327081]\n",
      " [0.33129449 0.23985016 1.         0.52115186 0.31451969 0.04402461]\n",
      " [0.         0.         0.52115186 1.         0.20464939 0.34071893]\n",
      " [0.62193243 0.10938785 0.31451969 0.20464939 1.         0.2639672 ]\n",
      " [0.24601928 0.04327081 0.04402461 0.34071893 0.2639672  1.        ]]\n",
      "\n",
      "\n",
      "Most similar to sentence 1:\n",
      "\tSentence 5 with similarity score 0.6219324252261071\n",
      "Most similar to sentence 2:\n",
      "\tSentence 1 with similarity score 0.28811542442208304\n",
      "Most similar to sentence 3:\n",
      "\tSentence 4 with similarity score 0.5211518578703335\n",
      "Most similar to sentence 4:\n",
      "\tSentence 3 with similarity score 0.5211518578703335\n",
      "Most similar to sentence 5:\n",
      "\tSentence 1 with similarity score 0.6219324252261071\n",
      "Most similar to sentence 6:\n",
      "\tSentence 4 with similarity score 0.3407189331492442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to apply bag of words model\n",
    "def bow_similarity(data):\n",
    "    vectorizer1 = CountVectorizer()\n",
    "    vocab = vectorizer1.fit(data)\n",
    "    X = vectorizer1.transform(data)\n",
    "    ###\n",
    "    print(\"A list of features:\")\n",
    "    print(\"====================\")\n",
    "    print(vocab.get_feature_names_out())\n",
    "\n",
    "    print(\"BOW-weighted document-term matrix:\")\n",
    "    print(\"======================================\")\n",
    "    dp1=pd.DataFrame(X.toarray(),columns=vocab.get_feature_names_out())\n",
    "    print(dp1)\n",
    "    ###\n",
    "    print(\"====================== \\n\")\n",
    "    print(\"k means clustering \\n\")\n",
    "    clustering(X)\n",
    "    return cosine_similarity(X)\n",
    "\n",
    "#importing TF using  parameter use_idf = False, norm = \"l1\"\n",
    "def tf_similarity(data):\n",
    "    vectorizer2 = TfidfVectorizer(use_idf = False, norm = \"l1\")\n",
    "    tf_vocab = vectorizer2.fit(data)\n",
    "    tf_matrix = vectorizer2.transform(data)\n",
    "    ###\n",
    "    print(\"A list of features:\")\n",
    "    print(\"====================\")\n",
    "    print(tf_vocab.get_feature_names_out())\n",
    "\n",
    "    print(\"Tf-weighted document-term matrix:\")\n",
    "    print(\"======================================\")\n",
    "    dp=pd.DataFrame(tf_matrix.toarray(),columns=tf_vocab.get_feature_names_out())\n",
    "    print(dp)\n",
    "    ###\n",
    "    print(\"====================== \\n\")\n",
    "    print(\"k means clustering \\n\")\n",
    "    clustering(tf_matrix)\n",
    "    return cosine_similarity(tf_matrix)\n",
    "\n",
    "# Importing TF-IDF using parameter norm = \"l2\"\n",
    "\n",
    "def tfidf_similarity(data):\n",
    "    vectorizer3 = TfidfVectorizer(norm = 'l2')\n",
    "    tfidf_vocab = vectorizer3.fit(data)\n",
    "    tfidf_matrix = vectorizer3.transform(data)\n",
    "    ###\n",
    "    print(\"A list of features:\")\n",
    "    print(\"====================\")\n",
    "    print(tfidf_vocab.get_feature_names_out())\n",
    "\n",
    "    print(\"Tf-idf-weighted document-term matrix:\")\n",
    "    print(\"======================================\")\n",
    "    dp=pd.DataFrame(tfidf_matrix.toarray(),columns=tfidf_vocab.get_feature_names_out())\n",
    "    print(dp)\n",
    "    ###\n",
    "    print(\"====================== \\n\")\n",
    "    print(\"k means clustering \\n\")\n",
    "    clustering(tfidf_matrix)\n",
    "    return cosine_similarity(tfidf_matrix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "methods = {\n",
    "    \"TF with Cosine Similarity\": tf_similarity,\n",
    "    \"Bag of words with Cosine Similarity\": bow_similarity,\n",
    "    \"TF-IDF with Cosine Similarity\": tfidf_similarity\n",
    "}\n",
    "\n",
    "# Apply the functions and print the similarity matrix and most similar sentences for each method\n",
    "for method, function in methods.items():\n",
    "    print('\\n')\n",
    "    print(\"====================================\")\n",
    "    print(f\"--- {method} ---\")\n",
    "    similarity_matrix = function(sentences['Text'])\n",
    "    print('\\n')\n",
    "    print(\"similarity matrix\")\n",
    "    print(similarity_matrix)\n",
    "    print('\\n')\n",
    "    \n",
    "    for i, row in enumerate(similarity_matrix):\n",
    "        most_similar = sorted([(j, score) for j, score in enumerate(row) if j != i], key=lambda x: x[1], reverse=True)[:1]\n",
    "        print(f\"Most similar to sentence {i+1}:\")\n",
    "        for j, score in most_similar:\n",
    "            print(f\"\\tSentence {j+1} with similarity score {score}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ae5fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
